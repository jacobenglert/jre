---
title: "2020 US Presidential Election Fraud Analysis"
author: "Jacob Englert"
date: 2020-11-17
output: md_document
# categories: ["R"]
# tags: ["R Markdown", "plot", "regression"]
---



<p>When the 2020 US Presidential election results started to come in, so did accusations of voter fraud. In several cases the accusations were quite unfounded, but a select few cited “statistical proof” of fraud. Many of the latter arguments referenced Benford’s law.</p>
<p><a href="https://en.wikipedia.org/wiki/Benford&#39;s_law">Benford’s law</a> describes the distribution of the leading digit of count data (e.g. the “1” in 100). It is based on the observation that in order to reach “2”, one must first go through “1”, and so on. Thus, higher digits are less frequently observed as the leading digit.</p>
<p>So how does this relate to voter fraud? Well, some might argue that the distribution of leading digits in a candidate’s votes across counties, states, etc., should follow Benford’s law. In other words, the probability of observing a leading digit of <span class="math inline">\(d\)</span> is given by:</p>
<p><span class="math display">\[P(d) = \log \left(1 + \frac{1}{d} \right), \quad d = 1, \ldots, 9\]</span>
… and if the observed vote tallies overwhelmingly depart from this distribution, then the counts are not reliable.</p>
<p>Now, comparing vote totals to the distribution dictated by Benford’s law cannot prove whether fraud exists or not for a variety of reasons. This <a href="https://www.reuters.com/article/uk-factcheck-benford-idUSKBN27Q3AI">article</a> makes some good points about where this argument falls apart. Also, it is always possible to make a type I error (i.e. declare fraud exists when it actually does not) with any statistical analysis.</p>
<p>But that’s no fun. So let’s take a look at election results from my lifetime and conduct an analysis of our own.</p>
<p>We will start by reading in a data set containing vote totals from all presidential elections since 2000. We have available to us for each candidate their party affiliation (democrat, republican, and other), as well as the total number of votes they received in every county in the country.</p>
<pre class="r"><code>library(tidyverse)
votes &lt;- read_csv(&#39;Data/votes.csv&#39;)
head(votes)
## # A tibble: 6 × 6
##    year state   county  candidate      party votes
##   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt; &lt;dbl&gt;
## 1  2000 Alabama Autauga Al Gore        DEM    4942
## 2  2000 Alabama Autauga George W. Bush REP   11993
## 3  2000 Alabama Autauga Other          Other   273
## 4  2000 Alabama Baldwin Al Gore        DEM   13997
## 5  2000 Alabama Baldwin George W. Bush REP   40872
## 6  2000 Alabama Baldwin Other          Other  1611</code></pre>
<p>Now we will summarize the frequency of leading digits in county votes, ignoring cases where no votes are available for the candidate. At this point we can also summarize the frequencies of county-level leading digits for across the entire country to perform a country-level analysis.</p>
<pre class="r"><code># Tally number of counties with each digit within state
state_digits &lt;- votes %&gt;%
  filter(votes &gt; 0 &amp; !is.na(votes)) %&gt;%
  mutate(digit = as.numeric(substr(votes,1,1))) %&gt;%
  summarise(n = n(), 
            .by = c(year, state, candidate, party, digit)) %&gt;%
  filter(digit %in% 1:9)

# Tally number of counties with each digit in the entire country
country_digits &lt;- state_digits %&gt;%
  summarise(n = sum(n),
            .by = c(year, candidate, party, digit))</code></pre>
<p>At this point it will also be helpful to store the expected frequences according to Benford’s law.</p>
<pre class="r"><code>benford &lt;- data.frame(digit = 1:9) %&gt;%
  mutate(exp = log(1 + 1 / digit, 10))</code></pre>
<p>Let’s begin by visualizing the actual frequencies for each party in every election:</p>
<pre class="r"><code>country_digits %&gt;%
  mutate(obs = n / sum(n),
         .by = c(year, candidate, party)) %&gt;%
  ggplot(aes(x = digit)) +
  geom_line(aes(y = obs, group = candidate, color = party)) +
  geom_col(data = benford, aes(y = exp), alpha = 0.3) +
  scale_x_continuous(breaks = 1:9) +
  facet_wrap(~year) +
  theme_bw() +
  labs(title = &quot;Do U.S. Presidential Elections Follow Benford&#39;s Law?&quot;,
       x = &#39;Leading Digit in Total Votes&#39;,
       y = &quot;% County Share (Expected vs. Observed)&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>In general, it would appear that the distribution of leading digits in nationwide county votes has closely followed Benford’s law in all elections since 2020 for all parties. But we should still formally test this. A common approach to comparing two distributions is a chi-squared goodness-of-fit test. This test compares the expected counts of each group to the observed counts, and provides a single <span class="math inline">\(\chi^2_{k-1}\)</span> test statistic. The <span class="math inline">\(k-1\)</span> degrees of freedom comes from the fact that given the total count, once the counts for <span class="math inline">\(k-1\)</span> of the <span class="math inline">\(k\)</span> groups are known, the last count must be determined. Further, we can calculate a p-value. Here I do this for all party-year-state combinations.</p>
<pre class="r"><code># State-level p-values
state_pvals &lt;- state_digits %&gt;%
  expand(nesting(year, candidate, state), digit) %&gt;%
  left_join(state_digits, by = join_by(year, candidate, state, digit)) %&gt;%
  mutate(n = replace_na(n, 0)) %&gt;%
  nest(.by = c(year, candidate, state)) %&gt;%
  mutate(pval = purrr::map(data, \(df) chisq.test(x = df$n, p = benford$exp)$p.value),
         flag = case_when(pval &lt; 0.01 ~ &#39;&lt; 0.01&#39;,
                          pval &lt; 0.05 ~ &#39;&lt; 0.05&#39;,
                          pval &lt; 0.10 ~ &#39;&lt; 0.10&#39;,
                          pval &gt; 0.10 ~ &#39;&gt; 0.10&#39;))
## Warning: There were 807 warnings in `mutate()`.
## The first warning was:
## ℹ In argument: `pval = purrr::map(data, function(df) chisq.test(x = df$n, p =
##   benford$exp)$p.value)`.
## Caused by warning in `chisq.test()`:
## ! Chi-squared approximation may be incorrect
## ℹ Run `dplyr::last_dplyr_warnings()` to see the 806 remaining warnings.</code></pre>
<p>The warnings we receive here are because certain digits have very low counts. For chi-squared test, it is often recommended that each group have at least 5 observations to it, otherwise the test statistic may not be reliable. One alternative one might try is a Fisher’s exact test, though that would be computationally very difficult for this setting. Another idea is to derive some test statistic based on a multinomial distribution. But for now, we will stick to the chi-squared test and take the results with a grain of salt.</p>
<p>We can also calculate p-values on the country scale. Let’s do that now.</p>
<pre class="r"><code># Country-level p-values
country_pvals &lt;- state_digits %&gt;%
  expand(nesting(year, candidate, state), digit) %&gt;%
  left_join(state_digits, by = join_by(year, candidate, state, digit)) %&gt;%
  mutate(n = replace_na(n, 0)) %&gt;%
  summarise(n = sum(n),
            .by = c(year, candidate, digit)) %&gt;%
  nest(.by = c(year, candidate)) %&gt;%
  mutate(pval = purrr::map(data, function(df) chisq.test(x = df$n, p = benford$exp)$p.value),
         flag = case_when(pval &lt; 0.01 ~ &#39;&lt; 0.01&#39;,
                          pval &lt; 0.05 ~ &#39;&lt; 0.05&#39;,
                          pval &lt; 0.10 ~ &#39;&lt; 0.10&#39;,
                          pval &gt; 0.10 ~ &#39;&gt; 0.10&#39;))</code></pre>
<p>Great! Now we have our p-values. Let’s check out some maps to see where and when each candidates has(n’t) experienced vote tallies that deviate from Benford’s law.</p>
<pre class="r"><code># Get US state map data
us_states &lt;- map_data(&quot;state&quot;) %&gt;%
  mutate(state = str_to_title(region))

# State Map
us_states %&gt;%
  left_join(state_pvals, by = join_by(state), relationship = &#39;many-to-many&#39;) %&gt;%
  filter(!is.na(year)) %&gt;%
  ggplot(aes(x = long, y = lat, group = group, fill = flag)) +
  geom_polygon(color = &#39;black&#39;) +
  coord_map(projection = &#39;albers&#39;, lat0 = 39, lat1 = 45) +
  scale_fill_manual(values = c(&#39;red&#39;,&#39;orange&#39;,&#39;yellow&#39;,&#39;gray&#39;)) +
  facet_wrap(year~candidate, nrow = 6, ncol = 3, dir = &#39;h&#39;) +
  labs(fill = &#39;P-value&#39;,
       x = &#39;Candidate&#39;,
       y = &#39;Year&#39;) +
  theme(axis.ticks = element_blank(),
        axis.text = element_blank())</code></pre>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-9"></span>
<img src="Figures/new_state_map.png" alt="State Map" width="90%" />
<p class="caption">
Figure 1: State Map
</p>
</div>
<p>On the state-level, we see that the majority of states have little evidence of departure from Benford’s law. On state in particular that stands out is Iowa, which was flagged with some degree of evidence in 14 out of 18 maps! It is also worth pointing out that all candidates had at least one state with questionable vote distributions.</p>
<pre class="r"><code>us &lt;- map_data(&quot;usa&quot;)

# US Map
us %&gt;%
  cross_join(country_pvals) %&gt;%
  filter(!is.na(year)) %&gt;%
  ggplot(aes(x = long, y = lat, group = group, fill = flag)) +
  geom_polygon(color = &#39;black&#39;) +
  coord_map(projection = &#39;albers&#39;, lat0 = 39, lat1 = 45) +
  scale_fill_manual(values = c(&#39;red&#39;,&#39;orange&#39;,&#39;yellow&#39;,&#39;gray&#39;)) +
  facet_wrap(year~candidate, nrow = 6, ncol = 3, dir = &#39;h&#39;) +
  labs(fill = &#39;P-value&#39;,
       x = &#39;Candidate&#39;,
       y = &#39;Year&#39;) +
  theme(axis.ticks = element_blank(),
        axis.text = element_blank())</code></pre>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="Figures/new_country_map.png" alt="Country Map" width="90%" />
<p class="caption">
Figure 2: Country Map
</p>
</div>
<p>On a nationwide scale, the most suspicious vote tallies occurred for republican Al Gore in 2000, democrat John Kerry in 2004, and the other parties in 2004. In both 2000 and 2020, vote tallies for all candidates had some level of suspicion.</p>
